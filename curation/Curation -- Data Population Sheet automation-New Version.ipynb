{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is to automate the creation of the data populationsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the final result is written in the following box folder. \n",
    "\n",
    "https://ibm.ent.box.com/folder/117380324021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is false, \n",
    "# when false, it will calculate the result based on all record (A, I, N)\n",
    "# when true, it will only calcualte based on active emplyee E01.CACTIVE = 'A'\n",
    "### change on 2020/11/18\n",
    "active_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_flag = '--' if not active_flag else ''\n",
    "na_flag\n",
    "'_active' if active_flag else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/odm_modules')\n",
    "from common_func import cloudant_conn as cc\n",
    "from common_func import odm_conn\n",
    "from common_func import odm_dict\n",
    "import pandas as pd\n",
    "import logging                                                                  \n",
    "import os  \n",
    "sys.path.append('/app')\n",
    "from BOX import box_oauth as box \n",
    "import openpyxl\n",
    "import datetime\n",
    "from openpyxl.styles import Color, PatternFill, Font, Border, Alignment\n",
    "from openpyxl.styles import colors\n",
    "from openpyxl.cell import Cell\n",
    "logging.basicConfig(stream=sys.stdout, level=20) \n",
    "from openpyxl.comments import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.cloudant_client.connect()\n",
    "odmmeta_api_root = 'https://odmmeta.dal1a.ciocloud.nonprod.intranet.ibm.com/igc/get_term/{}/format=text'\n",
    "df_busi= pd.DataFrame(list(cc.cloudant_client['busi_def']))\n",
    "busi_field_list = list(df_busi._id)\n",
    "busi_dict = df_busi.set_index('_id')['long_description'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with odm_conn.odm_adhoc('prod') as odmprd_adhoc:\n",
    "    result = odmprd_adhoc('''\n",
    "    select CISOCTRY,TISOCTRY from odmprd.odmt_countryiso \n",
    "    where CLANGUAG = '' AND FDISCONT <> 'Y' ''')\n",
    "    result_fdr = odmprd_adhoc('''\n",
    "    select cfdrsrc, tfdrsrc from odmprd.ODMT_FEEDSRCE\n",
    "    where clanguag = ''\n",
    "    ''')\n",
    "\n",
    "df_ctry = pd.DataFrame(result).applymap(lambda x: x.strip())\n",
    "ctry_dict = df_ctry.set_index('CISOCTRY').TISOCTRY.to_dict()\n",
    "\n",
    "df_fdr = pd.DataFrame(result_fdr).applymap(lambda x: x.strip())\n",
    "fdr_dict = df_fdr.set_index('CFDRSRC').TFDRSRC.to_dict()\n",
    "#fdr_dict['HD1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_flag is to switch if we will use the condition CACTIVE = A or not \n",
    "### change on 2020/11/18\n",
    "sql_temp = '''\n",
    "SELECT {tid}.COUNTRY \n",
    "{field_sum_list} \n",
    ", COUNT(*) AS TOTAL\n",
    "FROM \n",
    "(SELECT A.CCOUNTRY AS COUNTRY, A.* FROM ODMPRD.{tb_name} A, ODMPRD.ODMT_EMPLOYEE E01 \n",
    "WHERE \n",
    "E01.CCOUNTRY = A.CCOUNTRY\n",
    "AND E01.CCOUNTRQ = A.CCOUNTRQ\n",
    "AND E01.RSERNUM = A.RSERNUM \n",
    "{na_flag} AND E01.CACTIVE = 'A' \n",
    ") {tid}\n",
    "GROUP BY {tid}.COUNTRY ;\n",
    "'''\n",
    "sql_temp_fdr = '''\n",
    "SELECT {tid}.FDRSRC \n",
    "{field_sum_list} \n",
    ", COUNT(*) AS TOTAL\n",
    "FROM (\n",
    "SELECT E01.CFDRSRC AS FDRSRC, \n",
    "A.* FROM \n",
    "ODMPRD.ODMT_EMPLOYEE E01, \n",
    "ODMPRD.{tb_name} A\n",
    "WHERE \n",
    "E01.RSERNUM = A.RSERNUM\n",
    "AND E01.CCOUNTRY = A.CCOUNTRY\n",
    "AND E01.CCOUNTRQ = A.CCOUNTRQ\n",
    "{na_flag} AND E01.CACTIVE = 'A' \n",
    ") {tid}\n",
    "GROUP BY {tid}.FDRSRC ;\n",
    "'''\n",
    "\n",
    "sql_temp_d = '''\n",
    "SELECT {tid}.COUNTRY \n",
    "{field_sum_list} \n",
    ",COUNT(*) AS TOTAL\n",
    "FROM \n",
    "(SELECT CASE                                                         \n",
    "WHEN E1.CCOUNTRY IS NULL THEN SUBSTR('  ', 1, 2)             \n",
    "ELSE E1.CCOUNTRY END AS COUNTRY, A.*                         \n",
    "FROM ODMPRD.{tb_name} A                                            \n",
    "LEFT OUTER JOIN                                              \n",
    "ODMPRD.ODMT_EMPLOYEE E1                                      \n",
    "ON E1.RCNUM = A.RCNUM) {tid}                                   \n",
    "GROUP BY {tid}.COUNTRY ;           \n",
    "'''\n",
    "field_sum_temp = '''\\n, SUM(CASE WHEN {tid}.{field} = '{dft_value}' THEN 0 ELSE 1 END) AS {field} '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_dict.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tid = odm_dict.odm_tid_df_from_csv()\n",
    "df_col = odm_dict.odm_col_df_from_csv()\n",
    "df_col = df_col.loc[df_col.NAME !=''] # remove those line which could not be found in systable\n",
    "df_tid = df_tid.loc[df_tid.NAME !='']\n",
    "tid_dict = df_tid.set_index('CTID')['CTABNAME'].to_dict()\n",
    "tid_desc_dict = df_tid.set_index('CTID')['TTID'].to_dict()\n",
    "df_col['tid_col'] = df_col.CTID + '.' + df_col.CCOLNAME\n",
    "data_class_dict = df_col.set_index('tid_col').CCLASS.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population(tid, sql_template, idx_col = 'COUNTRY'):\n",
    "    logging.info('*'*10 + ' TID is {}'.format(tid))\n",
    "#    drop_list = ['CCOUNTRY', 'CCOUNTRQ', 'RSERNUM', 'CODM',  'CFDRSRC' ]\n",
    "#    drop_list = [ 'CODM', 'CCOUNTRQ', 'CFDRSRC' ]\n",
    "    drop_list = [ ]\n",
    "    tb_name = tid_dict[tid]\n",
    "    col_list = list(df_col.loc[df_col.CTID == tid].sort_values(by = 'COLNO')['CCOLNAME'])\n",
    "    col_list_filtered = list(filter(lambda field: field not in drop_list and 'SEQ' not in field, col_list))\n",
    "    field_sum_list =''.join( [field_sum_temp.format(\n",
    "        tid = tid, field = field, \n",
    "        dft_value = '0001-01-01' \n",
    "        if df_col.loc[(df_col.CTID == tid) & (df_col.CCOLNAME == field)].COLTYPE.values[0] == 'DATE'\n",
    "        else 0 if df_col.loc[(df_col.CTID == tid) & (df_col.CCOLNAME == field)].COLTYPE.values[0] in ['DECIMAL', \n",
    "                                                                                                      'SMALLINT', \n",
    "                                                                                                      'INTEGER', \n",
    "                                                                                                      'BIGINT']\n",
    "        else '' \n",
    "    ) for field in col_list_filtered])\n",
    "    ###\n",
    "    ### change on 2020/11/18, added na_flag\n",
    "    sql = sql_template.format(tid = tid, field_sum_list = field_sum_list, tb_name = tb_name, na_flag = '--' if not active_flag else '')\n",
    "    logging.debug(sql)\n",
    "\n",
    "    with odm_conn.odm_adhoc('prod') as odmprd_adhoc:\n",
    "        result = odmprd_adhoc(sql)\n",
    "\n",
    "    df = pd.DataFrame(result, columns = [idx_col, *col_list_filtered, 'TOTAL']).set_index(idx_col)\n",
    "    #print(df)\n",
    "    #print(df.sum)\n",
    "    df.loc['Total'] = df.sum()   \n",
    "    \n",
    "    # caculate the percentage\n",
    "    df['TEMP'] = df.RCNUM if 'RCNUM' in df.columns else df.RSERNUM\n",
    "    for col in [x for x in df.columns if x != 'TEMP']:\n",
    "        df[col] = df[col]/df.TEMP\n",
    "    df.drop(columns = ['TEMP'], inplace = True)\n",
    "    #pd.options.display.float_format = '{:.0f}%'.format\n",
    "    # enrich with country description and field desc\n",
    "##x    col_dict = df_col.loc[(df_col.CTID == tid), ['CCOLNAME', 'TCOLNAME']].set_index('CCOLNAME').TCOLNAME.to_dict()\n",
    "##x    df.columns = pd.MultiIndex.from_tuples([(col, col_dict.get(col,''), \n",
    "##x                                            data_class_dict.get(tid + '.' + col, ''))  \n",
    "##x                                            for col in df.columns], names = (None, None, None))\n",
    "    if not df.empty:\n",
    "        # reorder the fdr list\n",
    "        if idx_col == 'FDRSRC':\n",
    "            fdr_ordered_list = '''\n",
    "            HC9\tHHA\tHHE\tHHI\tHHJ\tHHP\tHNW\tHPH\tHSW\tHZA\tHEU\tHJ1\t\n",
    "            HBM\tHB8\tHB9\tHCE\tHC8\tHD1\tHD8\tHE2\tHF4\tHF8\tHF9\tHIN\t\n",
    "            HI7\tHI8\tHKR\tHOG\tHRH\tHSK\tHS1\n",
    "            '''.split()\n",
    "            #df_temp = pd.DataFrame(columns = ['Total', *fdr_ordered_list]).T # create an empty df\n",
    "            if tid == 'E01': # only reorder E01 table and other table will be aligned to E01 table. \n",
    "                ### 2020/11/18 change\n",
    "                #df = df.loc[['Total', *fdr_ordered_list]]\n",
    "                df = df.reindex(index = ['Total', *fdr_ordered_list] )\n",
    "            #df = pd.concat([df_temp, df], axis = 1)\n",
    "        else: \n",
    "\n",
    "            temp_idx = list(df.index)\n",
    "            temp_idx.remove('Total')\n",
    "            ### 2020/11/18 change\n",
    "            #df = df.loc[['Total', *temp_idx]]\n",
    "            df = df.reindex(index = ['Total', *temp_idx])\n",
    "        # determine which dictionary to be used based on index column name\n",
    "        df.index = [ 'blank' if idx.strip() == '' else idx   for idx in df.index] # rename the blank value to be string blank\n",
    "##x        mapping_dict = fdr_dict if idx_col == 'FDRSRC' else ctry_dict \n",
    "##x        df.index = pd.MultiIndex.from_tuples([(ctry_fdr, mapping_dict.get(ctry_fdr,''))  for ctry_fdr in df.index])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should only used when finally write to excel file\n",
    "def add_desc(tid, df, idx_col = 'COUNTRY'): # add desc into index and columns using disctionary\n",
    "    col_dict = df_col.loc[(df_col.CTID == tid), ['CCOLNAME', 'TCOLNAME']].set_index('CCOLNAME').TCOLNAME.to_dict()\n",
    "#    print(col_dict)\n",
    "#    print(df.columns)\n",
    "    \n",
    "    df.index = pd.MultiIndex.from_tuples([(col, col_dict.get(col,''), \n",
    "                                            data_class_dict.get(tid + '.' + col, ''))  \n",
    "                                            for col in df.index], names = (None, None, None))\n",
    "    if not df.empty:\n",
    "        mapping_dict = fdr_dict if idx_col == 'FDRSRC' else ctry_dict \n",
    "        df.columns = pd.MultiIndex.from_tuples([(ctry_fdr, mapping_dict.get(ctry_fdr,''))  for ctry_fdr in df.columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_list = list(filter(lambda x: x!='' \n",
    "                       and x[0] in ['D']\n",
    "                       and x not in ['D19', 'D20']\n",
    "#                       and x in ['D01', 'D02']  \n",
    "                       , list(df_tid.CTID.drop_duplicates())))\n",
    "logging.info(str(tid_list))\n",
    "dfs_d ={tid: get_population(tid, sql_temp_d).T.fillna(0) for tid in tid_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_list = list(filter(lambda x: x!='' \n",
    "                       and x[0] in ['E', 'F']\n",
    "#                       and x == 'E03'\n",
    "                       ,list(df_tid.CTID.drop_duplicates())))\n",
    "logging.info(str(tid_list))\n",
    "dfs_ef ={tid: get_population(tid, sql_temp).T.fillna(0) for tid in tid_list}\n",
    "#tid_list = list(filter(lambda x: x!='' \n",
    "#                       and x[0] in ['E', 'F']\n",
    "#                       and x in ['E01', 'E02', 'E03', 'F01']\n",
    "#                       ,list(df_tid.CTID.drop_duplicates())))\n",
    "dfs_fdr = {tid: get_population(tid, sql_temp_fdr, idx_col = 'FDRSRC').T.fillna(0) for tid in tid_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code is to generate all the sample value for each field. \n",
    "\n",
    "1. We only check non PI data, which started with R, T, C and it is char type\n",
    "2. when the count of that field is less then 40, we try to get the first 10 most frequent sample values from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_d['D03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of distinct values\n",
    "sql_temp_cnt = '''\n",
    "select \n",
    "{col_cnt_list}\n",
    "from odmprd.{tbname} {tid}\n",
    "'''\n",
    "\n",
    "def get_cnt(tid): \n",
    "    tbname = tid_dict.get(tid, '')\n",
    "    ### following the filter is to get all the in-scope columns from the list\n",
    "    col_list_all = df_col.loc[(df_col.CTID == tid) & \n",
    "                              (((df_col.CCLASS == 'O') & df_col.CCOLNAME.apply(lambda x: len(x) > 1 and x[0] in ['R', 'T', 'C'] ) ) \n",
    "                              | df_col.CCOLNAME.apply(lambda x: len(x) > 1 and x[0] in [ 'C', 'F'] ))\n",
    "                              & (df_col.CCOLNAME != 'CSPSSOCS')  # Remove one SSN field\n",
    "                          & (df_col.COLTYPE == 'CHAR')\n",
    "                         ].CCOLNAME\n",
    "    \n",
    "    col_list_list = [col_list_all[x:x+3] for x in range(0, len(col_list_all), 3)]\n",
    "    print(col_list_list)\n",
    "    \n",
    "    with odm_conn.odm_adhoc('prod') as odmprd_adhoc: \n",
    "        def chunk_count(col_list): \n",
    "            col_cnt_list = [\"COUNT(DISTINCT {}) AS {}\".format(col, col) for col in col_list]\n",
    "            col_cnt_list = '\\n,'.join(col_cnt_list)\n",
    "            sql = sql_temp_cnt.format(col_cnt_list = col_cnt_list, tbname = tbname, tid = tid)\n",
    "            print(sql)\n",
    "            result = odmprd_adhoc(sql)\n",
    "            df_temp = pd.DataFrame(result)\n",
    "            df_temp.index = ['distinct_cnt']\n",
    "            return df_temp\n",
    "\n",
    "        df = pd.concat([chunk_count(col_list)  for col_list in col_list_list] \n",
    "                       if len(col_list_list) !=0 else [pd.DataFrame()], axis = 1)\n",
    "    \n",
    "    return tid, df\n",
    "\n",
    "# only D table and E table will be checked. \n",
    "#dfs = dict([get_cnt(tid) for tid in tid_dict.keys() if tid != '' and tid[0:3] in ['E02', 'D01']])\n",
    "dfs = dict([get_cnt(tid) for tid in tid_dict.keys() if tid != '' and tid[0] in ['E', 'D']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 10 most frequent values \n",
    "\n",
    "def get_distinct_value(tid, threshhold):\n",
    "    if dfs[tid].empty:\n",
    "        return ''\n",
    "    col_list = [x[0] for x in dfs[tid].iloc[0].items() if x[1]<=threshhold or threshhold == 0]\n",
    "    sql_temp_distinct = '''\n",
    "    select {col}, count(*) AS CNT from odmprd.{tbname} {tid} \n",
    "    where {col} <> ''\n",
    "    group by {col}\n",
    "    order by count(*) DESC\n",
    "    fetch first 10 rows only \n",
    "    '''\n",
    "    sqls = [sql_temp_distinct.format(tid = tid, tbname = tid_dict[tid], col=col) for col in col_list]\n",
    "    for sql in sqls: \n",
    "        print(sql)\n",
    "    with odm_conn.odm_adhoc('prod') as odmprd_adhoc:\n",
    "        results = [odmprd_adhoc(sql) for sql in sqls]\n",
    "        df_tmps = [pd.DataFrame(result) for result in results]\n",
    "        df_tmps = [df.drop(columns = ['CNT']).applymap(lambda x: x.strip()) for df in df_tmps if not df.empty]\n",
    "\n",
    "    ser = pd.Series( {df.columns[0]: '; '.join(df.values.flat) for df in df_tmps})\n",
    "    return ser\n",
    "\n",
    "# 40 is the threshold\n",
    "# if threshhold == 0, then it means no threshhold\n",
    "#sers = {tid: get_distinct_value(tid, 40) for tid in dfs.keys()}\n",
    "sers = {tid: get_distinct_value(tid, 0) for tid in dfs.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_distinct = dict()\n",
    "for tid, df in dfs.items():\n",
    "    df = df.T\n",
    "    df['Top 10 non-blank values'] = sers[tid]\n",
    "    dfs_distinct[tid] = df.fillna('')\n",
    "    if not dfs_distinct[tid].empty:\n",
    "        #dfs_distinct[tid].distinct_cnt = dfs_distinct[tid].distinct_cnt.astype(int)\n",
    "        dfs_distinct[tid].distinct_cnt = dfs_distinct[tid].distinct_cnt.apply(lambda x: '<=10' if x<=10 else '<=40' if x<=40 else '>40' )\n",
    "#dfs_distinct = pd.concat(dfs_distinct.values())\n",
    "dfs_distinct['E01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx2_file = '10 top distinct values.xlsx'\n",
    "with pd.ExcelWriter(xlsx2_file) as writer: \n",
    "    for tid, df in dfs_distinct.items():\n",
    "        df.to_excel(writer, sheet_name=  tid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat the dfs_ef dfs_d df_fdr with dfs_distinct to get the dfs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the distinct count and sample values\n",
    "dfs_final = dict()\n",
    "dfs_fdr_final = dict()\n",
    "\n",
    "for tid, df in [ *(dfs_ef.items()), *(dfs_d.items())]:\n",
    "    dfs_final[tid] = pd.concat([df, dfs_distinct.get(tid,pd.DataFrame(columns = ['distinct_cnt', 'Top 10 non-blank values']) )],\n",
    "                               axis = 1)\n",
    "for tid, df in dfs_fdr.items(): \n",
    "    dfs_fdr_final[tid] = pd.concat([df , dfs_distinct.get(tid,pd.DataFrame(columns = ['distinct_cnt', 'Top 10 non-blank values'])) ], \n",
    "                           axis = 1)\n",
    "\n",
    "#dfs_final ={tid: add_desc(tid, df) if tid != 'FDR' \n",
    "#            else add_desc('E01', df_fdr_new, idx_col = 'FDRSRC')\n",
    "#            for tid, df in [('FDR', df_fdr_new)  , *dfs_final.items()]}\n",
    "\n",
    "dfs_final = {tid: add_desc(tid, df) for tid, df in dfs_final.items()}\n",
    "dfs_fdr_final = {'FDR_{}'.format(tid): add_desc(tid, df, idx_col = 'FDRSRC') for tid, df in dfs_fdr_final.items()}\n",
    "dfs_final = {**dfs_final, **dfs_fdr_final} \n",
    "#dfs_final['FDR'] = add_desc('E01', df_fdr_new, idx_col = 'FDRSRC')\n",
    "#df_exx = pd.concat([dfs_final[tid] ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge those E, F table into one single sheet\n",
    "dfs_efx = []\n",
    "for tid in filter(lambda x: x[0] in ['E' ,'F'] and 'FDR' not in x , dfs_final.keys()):\n",
    "    df = dfs_final[tid].copy()\n",
    "    df = df.loc[filter(lambda idx: idx != ('TOTAL', '', ''),df.index)] # remove the total line since it is meaningless\n",
    "    df.index =pd.MultiIndex.from_tuples([(*idx, tid)   for idx in df.index])\n",
    "    dfs_efx.append(df)\n",
    "    \n",
    "df_exx = pd.concat(dfs_efx)\n",
    "df_exx = df_exx[dfs_final['E01'].columns]\n",
    "df_exx\n",
    "\n",
    "dfs_fdr_merged = []\n",
    "for key in filter(lambda x: 'FDR' in x , dfs_final.keys()):\n",
    "    df = dfs_final[key].copy()\n",
    "    df = df.loc[filter(lambda idx: idx != ('TOTAL', '', ''),df.index)] # remove the total line since it is meaningless\n",
    "    df.index =pd.MultiIndex.from_tuples([(*idx, key[-3:])   for idx in df.index])\n",
    "    dfs_fdr_merged.append(df)\n",
    "    \n",
    "df_fdr = pd.concat(dfs_fdr_merged)\n",
    "df_fdr = df_fdr[dfs_final['FDR_E01'].columns]\n",
    "df_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fdr_copy is the summary table\n",
    "df_fdr_copy = df_fdr.copy()\n",
    "df_fdr_copy.index.names = ('A', \"B\", \"C\", 'TID')\n",
    "df_fdr_copy.reset_index(inplace = True)\n",
    "df_fdr_copy = df_fdr_copy.drop(columns = [('A'), ('B', ), ('C', ), ('Total', )])\n",
    "df_fdr_copy = df_fdr_copy.groupby('TID').agg(lambda s: '' if s.isnull().all() else s.mean())\n",
    "df_fdr_copy.index = pd.MultiIndex.from_tuples( (x, tid_dict.get(x, ''), tid_desc_dict.get(x, ''))   for x in df_fdr_copy.index)\n",
    "\n",
    "df_exx_copy = df_exx.copy()\n",
    "df_exx_copy.index.names = ('A', \"B\", \"C\", 'TID')\n",
    "df_exx_copy.reset_index(inplace = True)\n",
    "df_exx_copy = df_exx_copy.drop(columns = [('A'), ('B', ), ('C', ), ('Total', )])\n",
    "df_exx_copy = df_exx_copy.groupby('TID').agg(lambda s: '' if s.isnull().all() else s.mean())\n",
    "df_exx_copy.index = pd.MultiIndex.from_tuples( (x, tid_dict.get(x, ''), tid_desc_dict.get(x, ''))   for x in df_exx_copy.index)\n",
    "\n",
    "\n",
    "#df_fdr_copy.iloc[:, [0,1]]\n",
    "#df_fdr_copy.iloc[1057, 1].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### change on 2020/11/18\n",
    "###\n",
    "xlsx_file = 'data_population_masked_percentage{}.xlsx'.format('_active' if active_flag else '')\n",
    "with pd.ExcelWriter(xlsx_file) as writer: \n",
    "    for tid, df in[('EFx', df_exx), ('FDR', df_fdr), ('FDRSUM', df_fdr_copy), ('ExxSUM', df_exx_copy), *dfs_final.items()]:\n",
    "        df.to_excel(writer, sheet_name=  tid )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xlsx1_file = 'data_population_masked_percentage_stacked.xlsx'\n",
    "for tid, df in [*(dfs_ef.items()), *(dfs_d.items())]:\n",
    "    df.index = pd.MultiIndex.from_tuples((tid,a,b,c)  for (a,b,c) in df.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all = pd.concat([df for tid, df in  [*(dfs_ef.items()), *(dfs_d.items())]])\n",
    "df_all.to_excel(xlsx1_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the data with color coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small change in the layout of the sheet\n",
    "xfile = openpyxl.load_workbook(xlsx_file)\n",
    "for tid in xfile.sheetnames:\n",
    "    sheet = xfile[tid]\n",
    "    sheet.insert_rows(1)\n",
    "    sheet.delete_rows(4,1)\n",
    "xfile.save(xlsx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the color coding on the sheet. no tweak on the existing cells. \n",
    "cur_time = str(datetime.datetime.now())\n",
    "greenFill = PatternFill(start_color='CCCCFF11',\n",
    "               end_color='CCCCFF11',\n",
    "               fill_type='solid')\n",
    "lightRedFill = PatternFill(start_color='00EEAAEE',\n",
    "               end_color='00EEAAEE',\n",
    "               fill_type='solid')\n",
    "redFill = PatternFill(start_color='00EE6600',\n",
    "               end_color='00EE6600',\n",
    "               fill_type='solid')\n",
    "colFill = PatternFill(start_color='CCCCCCFF',\n",
    "               end_color='CCCCCCFF',\n",
    "               fill_type='solid')\n",
    "rowFill = PatternFill(start_color='AAEEEECC',\n",
    "               end_color='AAEEEECC',\n",
    "               fill_type='solid')\n",
    "\n",
    "greyFill = PatternFill(start_color='CCCCCCCC',\n",
    "               end_color='CCCCCCCC',\n",
    "               fill_type='solid')\n",
    "naFill = PatternFill(start_color='EECCFFFF',\n",
    "               end_color='EECCFFFF',\n",
    "               fill_type='solid')\n",
    "color = ['00DDDDDD', '00CCCCCC', '00AAAAAA' ,'00888888', '00666666'  ]\n",
    "colorFill = [PatternFill(start_color=c, end_color=c,fill_type='solid') for c in color]\n",
    "\n",
    "xfile = openpyxl.load_workbook(xlsx_file)\n",
    "for tid in xfile.sheetnames:\n",
    "    sheet = xfile[tid]\n",
    "    #sheet.insert_rows(1)\n",
    "    #tid = 'E01' if tid == 'FDR' else tid\n",
    "    sheet['A1'] = tid\n",
    "    sheet['B1'] = tid_dict.get(tid if 'FDR' not in tid  else tid[-3:] , '') \n",
    "    sheet['C1'] = tid_desc_dict.get(tid if 'FDR' not in tid  else tid[-3:] , '') + ':' + cur_time\n",
    "    #sheet['D1'] = cur_time\n",
    "    sheet['A3'] = 'ODM Field' if tid not in  ['FDRSUM', 'ExxSUM'] else 'TID'\n",
    "    sheet['B3'] = 'Description' if tid not in  ['FDRSUM', 'ExxSUM'] else 'Table Name'\n",
    "    sheet['C3'] = 'Data class' if tid not in  ['FDRSUM', 'ExxSUM'] else 'Table description'\n",
    "    if tid in ['EFx', 'FDR']:\n",
    "        sheet['D3'] = 'TID'\n",
    "\n",
    "    # delete the empty row\n",
    "    #sheet.delete_rows(4,1)\n",
    "\n",
    "    # fill color\n",
    "    for row in sheet.iter_rows(min_row=1, max_col=sheet.max_column, max_row=1):\n",
    "        for cell in row:\n",
    "            cell.fill = greenFill\n",
    "\n",
    "    # fill grey every other row\n",
    "#    switch = 0\n",
    "#    for row in sheet.iter_rows(min_row=4, max_col= sheet.max_column, min_col = 3 , max_row=sheet.max_row):\n",
    "#        if switch == 0: \n",
    "#            for cell in row:\n",
    "#                cell.fill = greyFill\n",
    "#            switch = 1\n",
    "#        else:\n",
    "#            switch = 0\n",
    "\n",
    "    # the contents, max_col -2 is to ignore the last 2 columns which are for distinct count and sample values\n",
    "    for row in sheet.iter_rows(min_row=4, \n",
    "                               max_col=sheet.max_column-2 if tid not in  ['FDRSUM', 'ExxSUM'] else sheet.max_column, \n",
    "                               max_row=sheet.max_row, \n",
    "                               min_col = 4 if tid not in ['EFx', 'FDR'] else 5):\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='right')\n",
    "\n",
    "            cell.font = Font(color = '000000')\n",
    "            if isinstance(cell.value, (int, float)):\n",
    "                if float(cell.value) == 0:\n",
    "                    cell.fill = PatternFill(start_color='00FFFFFF', end_color='00FFFFFF',fill_type='solid')\n",
    "                    cell.number_format = '0'\n",
    "                elif float(cell.value) < 0.2: \n",
    "                    cell.fill = colorFill[0]\n",
    "                    cell.number_format = '0.00%'\n",
    "                elif float(cell.value) < 0.4: \n",
    "                    cell.number_format = '0.00%'\n",
    "                    cell.fill = colorFill[1]\n",
    "                elif float(cell.value) < 0.6: \n",
    "                    cell.font = Font(color = 'FFFFFF')\n",
    "                    cell.number_format = '0.00%'\n",
    "                    cell.fill = colorFill[2]\n",
    "                elif float(cell.value) < 0.8: \n",
    "                    cell.number_format = '0.00%'\n",
    "                    cell.font = Font(color = 'FFFFFF')\n",
    "                    cell.fill = colorFill[3]\n",
    "                else: \n",
    "                    cell.number_format = '0.00%'\n",
    "                    cell.fill = colorFill[4]\n",
    "                    cell.font = Font(color = 'FFFFFF')\n",
    "            else : \n",
    "                cell.fill = naFill\n",
    "\n",
    "    # this is for the columns distinct_cnt and top 10 non blank values columns\n",
    "    if tid not in  ['FDRSUM', 'ExxSUM']:\n",
    "        for row in sheet.iter_rows(min_row=2, \n",
    "                                   max_col=sheet.max_column, \n",
    "                                   max_row=sheet.max_row, \n",
    "                                   min_col = sheet.max_column-1):\n",
    "            for cell in row:\n",
    "                cell.fill = PatternFill(start_color='00FFFFFF', end_color='00FFFFFF',fill_type='solid')\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "                cell.font = Font(color = 'A000A0')\n",
    "                \n",
    "    # the columns fields (country & feedr)\n",
    "    for row in sheet.iter_rows(min_row=2, \n",
    "                               max_col=sheet.max_column, \n",
    "                               min_col = 4 if tid not in ['EFx', 'FDR']  else 5, \n",
    "                               max_row=3):\n",
    "        for cell in row:\n",
    "            cell.fill = colFill\n",
    "            cell.alignment = Alignment(horizontal='left')\n",
    "    # the index fields description(odm data fields)\n",
    "    for row in sheet.iter_rows(min_row=3, \n",
    "                               max_col= 3 if tid not in ['EFx', 'FDR'] else 4, \n",
    "                               min_col = 1 , \n",
    "                               max_row=sheet.max_row):\n",
    "        if row[2].value == 'PI':\n",
    "            for cell in row:\n",
    "                cell.fill = lightRedFill\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "        elif row[2].value == 'SPI':\n",
    "            for cell in row:\n",
    "                cell.fill = redFill\n",
    "                cell.font = Font(color = 'FFFFFF')\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "        else: \n",
    "            for cell in row:\n",
    "                cell.fill = rowFill\n",
    "                cell.alignment = Alignment(horizontal='left')\n",
    "    # the data field name , check if business definition is avaiale, if yes, put the hyperlink \n",
    "    \n",
    "    for row in sheet.iter_rows(min_row=3, max_col= 1, min_col = 1 , max_row=sheet.max_row):\n",
    "        for cell in row:\n",
    "            if cell.value in busi_field_list:\n",
    "                cell.hyperlink = odmmeta_api_root.format(cell.value)\n",
    "                cell.font =Font(color = '0000FF')\n",
    "    \n",
    "    # adjust the 2nd column width\n",
    "    #cell_columns = list(sheet.columns)[2]\n",
    "    #length = max(len(str(cell.value)) if cell.value is not None else 0 for cell in cell_columns)\n",
    "    sheet.column_dimensions['B'].width = 37\n",
    "    sheet.column_dimensions['A'].width = 10\n",
    "    sheet.freeze_panes = sheet['D4'] if tid not in ['EFx', 'FDR'] else sheet['E4']\n",
    "            \n",
    "xfile.save(xlsx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id = '117380324021'  # METATEST folder\n",
    "from BOX import box_oauth as box  \n",
    "client = box.get_box_client()\n",
    "box.save2box_folder(client, folder_id, xlsx_file) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Color selection template\n",
    "xlsx_file1 = 'temp2.xlsx'\n",
    "xfile1 = openpyxl.load_workbook(xlsx_file1)\n",
    "start_color = '{}{}{}{}'\n",
    "sheet = xfile1['Sheet1']\n",
    "var_input = ['{}{}'.format(x,x) for x in \"ECA86420\"]\n",
    "\n",
    "gen_color = (a+b+c+d  for a in var for b in var for c in var for d in var)\n",
    "for row in sheet.iter_rows( max_col=64, max_row=64):\n",
    "    for cell in row:\n",
    "        x = next(gen_color)\n",
    "        print(x)\n",
    "        colorFill = PatternFill(start_color=x,\n",
    "                   end_color=x,\n",
    "                   fill_type='solid')\n",
    "        cell.value = x\n",
    "        cell.fill = colorFill\n",
    "        cell.font = Font(color = '000000')\n",
    "\n",
    "\n",
    "xfile1.save(xlsx_file1)                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xlsx_file = 'data_population_masked.xlsx'\n",
    "with pd.ExcelWriter(xlsx_file) as writer: \n",
    "    for tid, df in [('FDR', df_fdr), *(dfs_ef.items()), *(dfs_d.items())]:\n",
    "        #df.T.applymap(lambda x: 'Y' if x != 0 else 'N').to_excel(writer, sheet_name=  tid )        \n",
    "        df.T.applymap(lambda x: 'Y' if x != 0 else 'N').to_excel(writer, sheet_name=  tid )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xlsx_file = 'data_population.xlsx'\n",
    "with pd.ExcelWriter(xlsx_file) as writer: \n",
    "    for tid, df in [('FDR', df_fdr), *(dfs_ef.items()), *(dfs_d.items())]:\n",
    "        df.T.to_excel(writer, sheet_name=  tid )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "col_list_all = df_col.loc[(df_col.CTID == 'E01') & \n",
    "                          (((df_col.CCLASS == 'O') & df_col.CCOLNAME.apply(lambda x: len(x) > 1 and x[0] in ['R', 'T', 'C'] ) ) \n",
    "                          | df_col.CCOLNAME.apply(lambda x: len(x) > 1 and x[0] in [ 'C', 'F'] ))\n",
    "                          & (df_col.CCOLNAME != 'CSPSSOCS')  # Remove one SSN field\n",
    "                      & (df_col.COLTYPE == 'CHAR')\n",
    "                     ].CCOLNAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in col_list_all:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = box.get_box_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_source = client.file(602746204741).get().name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col.loc[(df_col.CTID == 'E01') & (df_col.TCOLNAME.str.contains('Absence'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(client.file('731566115825').content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
