{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is to ingest the ddl definition into cloudant database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember:**   \n",
    "the mapping /result in docker image is mapped to local folder ~/Documents/GitHub/jupyter/result  \n",
    "the mapping /input in docker image is mapped to local folder ~/Documents/GitHub/jupyter/input\n",
    "\n",
    "link to the cloudanta database is here:   \n",
    "https://d5e8ab56-62ce-4345-b1f2-33e670691507-bluemix.cloudant.com/dashboard.html \n",
    "\n",
    "The following code is to ingest the ddl into cloudant database. \n",
    "\n",
    "1. ftp to get the file from server stfmvs1\n",
    "1. parse the ddl unload to list of ddls\n",
    "1. merge the tid information from rz1 and rz3 cloudant database\n",
    "1. populate the ddl information into cloudant database.\n",
    "\n",
    "Before run this notebook, please submit the jcl in `ODMLD.PRD.RUN(ODMDDLRJ)` first on the stfmvs1 server\n",
    "the result file on the server will be `C943511.RES.GENSQL.ODM` and `C943511.RES.GENSQL.ODMR` \n",
    "\n",
    "the MQT for ODM: `ODMLD.PRD.RUN(ODMDDMQT)` , the result is in `C943511.RES.GENSQL.ODM.MQT*`  \n",
    "the MQT for ODMR: `ODMLD.PRD.RUN(ODMDDLMQ)`, the result is in `C943511.RES.GENSQL.ODMR.MQT*`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/odm_modules')\n",
    "from common_func import cloudant_conn\n",
    "from common_func import odm_ftp\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['CLOUDANT_USER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the cloudant_db_name and get the tid information which can be used to enrich the tid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environ_suffix = '_test'\n",
    "environ_suffix = ''   # when production usage\n",
    "\n",
    "cloudant_db_name = 'ddl{}'.format(environ_suffix) # the cloudant database name to be ingested\n",
    "cloudant_conn.cloudant_client.connect()\n",
    "df_rz1 = pd.DataFrame(list(cloudant_conn.cloudant_client['rz1{}'.format(environ_suffix)]))\n",
    "df_rz3 = pd.DataFrame(list(cloudant_conn.cloudant_client['rz3{}'.format(environ_suffix)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unload the MQT files for both ODM and ODMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odmr_mqt_file = ['odmr_mqt_ddl{}.txt'.format(str(i+1)) for i in range(3)]\n",
    "odm_mqt_file = ['odm_mqt_ddl{}.txt'.format(str(i+1)) for i in range(3)]  \n",
    "#print(odm_mqt_file)\n",
    "# the file name in the folder input\n",
    "with odm_ftp.odm_ftp_conn('get') as odm_get_file: \n",
    "    [odm_get_file(fm = 'C943511.RES.GENSQL.ODM.MQT{}'.format(str(i+1)), to= '/input/{}'.format(file_name)) \n",
    "     for i,file_name in enumerate(odm_mqt_file)]\n",
    "    [odm_get_file(fm = 'C943511.RES.GENSQL.ODMR.MQT{}'.format(str(i+1)), to= '/input/{}'.format(file_name)) \n",
    "     for i,file_name in enumerate(odmr_mqt_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_mqt_texts = [open('/input/{}'.format(file_name), 'r').read() for file_name in odm_mqt_file]\n",
    "odm_mqt_texts = [re.sub('--    Materialized Query Table=', '--    View=', text, re.I) for text in odm_mqt_texts]\n",
    "odm_mqt_texts = [re.sub('\\n\\s*COMMIT;\\s*\\n', '\\n', text, re.I) for text in odm_mqt_texts]\n",
    "\n",
    "odmr_mqt_texts = [open('/input/{}'.format(file_name), 'r').read() for file_name in odmr_mqt_file]\n",
    "odmr_mqt_texts = [re.sub('--    Materialized Query Table=', '--    View=', text, re.I) for text in odmr_mqt_texts]\n",
    "odmr_mqt_texts = [re.sub('\\n\\s*COMMIT;\\s*\\n', '\\n', text, re.I) for text in odmr_mqt_texts]\n",
    "    \n",
    "odm_mqt_text = '\\n'.join(odm_mqt_texts)\n",
    "odmr_mqt_text = '\\n'.join(odmr_mqt_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unload the file frome stfmvs1 server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odmr_file = 'odmr_ddl.txt' # this is the final file name\n",
    "odm_file = 'odm_ddl.txt'  \n",
    "\n",
    "odmr_view_file = 'odmr_view_ddl.txt'\n",
    "odm_view_file = 'odm_view_ddl.txt'  \n",
    "with odm_ftp.odm_ftp_conn('get') as odm_get_file:\n",
    "    odm_get_file(fm = 'C943511.RES.GENSQL.ODMR', to= '/input/{}'.format(odmr_view_file))\n",
    "    odm_get_file(fm = 'C943511.RES.GENSQL.ODM', to= '/input/{}'.format(odm_view_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT    Attach MQT ddl into the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/input/{}'.format(odm_file), 'w') as f:\n",
    "    text = open('/input/{}'.format(odm_view_file), 'r').read()\n",
    "    text = re.sub('\\n\\s*COMMIT;\\s*\\n', '\\n', text, re.I) #remove the last COMMIT\n",
    "    f.write(text)\n",
    "    f.write(odm_mqt_text)\n",
    "with open('/input/{}'.format(odmr_file), 'w') as f:\n",
    "    text = open('/input/{}'.format(odmr_view_file), 'r').read()\n",
    "    text = re.sub('\\n\\s*COMMIT;\\s*\\n', '\\n', text, re.I) #remove the last COMMIT\n",
    "    f.write(text)\n",
    "    f.write(odmr_mqt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_text = open('/input/{}'.format(odm_file), 'r').read()\n",
    "odmr_text = open('/input/{}'.format(odmr_file), 'r').read()\n",
    "odm_text +=odmr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddls_odm = re.split('COMMIT\\s*;', odm_text, flags = re.I)\n",
    "ddls_odm = re.split('--    View=.*?\\n', odm_text, flags = re.I)\n",
    "#ddls_odm = ddls_odm[0:-1]\n",
    "print(\"Total number of ddl are : {}\".format(len(ddls_odm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ddl(ddl_stmt):\n",
    "    ddl_lines = ddl_stmt.split('\\n')\n",
    "    ddl_lines = list( filter(lambda x: x.lstrip()[0:2] != '--'   , ddl_lines) )\n",
    "    ddl_lines = list(filter(lambda x: not (x.lstrip()[0:3] == 'SET' and x.rstrip()[-1] == ';'), ddl_lines ) )\n",
    "#    ddl_lines = filter(lambda x: not (x.lstrip()[0:6] == 'COMMIT' and x.rstrip()[-1]== ';'), ddl_lines) # remove commit ; \n",
    "    ddl_lines = [' ' if i.strip() =='' else i.strip() if i.strip()[-1]=='.' else i.strip()+ ' ' for i in ddl_lines]\n",
    "    ddl_lines = [stmt.strip(';').strip() for stmt in ddl_lines]\n",
    "    ddl = \"\\n\".join(ddl_lines).strip() # turn multiple lines into one single line.\n",
    "    return ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddls_odm = list(map(process_ddl, ddls_odm))\n",
    "ddls_odm = list(filter(lambda ddl: ddl != '', ddls_odm))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ddls_odm[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ddl(ddl):\n",
    "    p = re.compile(r'CREATE\\s+(?:VIEW|TABLE)\\s+(\\w+)\\.(\\w+).*?AS(.*)', re.I|re.S)   # v0.19 compatible for handle mqt\n",
    "    p1 = re.compile(r'CREATE\\s+(?:VIEW|TABLE)\\s+(\\w+)\\.(\\w+)\\s*\\(([^()]*)\\).*?AS(.*)', re.I|re.S) #v0.19 compatible for hadle mqt\n",
    "    x = p.match(ddl)\n",
    "    x1 = p1.match(ddl)\n",
    "    x = x1 if x1 is not None else x  # first check x1, x1 always takes more information from the ddl\n",
    "    schema, view_name, view_query = x.groups()[0], x.groups()[1], x.groups()[-1]\n",
    "    return {\"view_name\": view_name, \"ddl\": ddl, \"schema\": schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddls_odm = list(map(parse_ddl, ddls_odm))\n",
    "#list(map(lambda x: print(x['view_name']), ddls_odm))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ddls_odm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ddls_odm)\n",
    "dfs = pd.concat([df_rz1, df_rz3]).rename(columns = {'_id': 'table_id'})\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dfs.drop(columns = ['_rev', 'src', 'description', 'alter_id']), left_on = 'view_name', right_on = 'table_name', how = 'left').drop(columns = ['table_name']).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res  = cloudant_conn.df_2_cloudant(df, cloudant_db_name, mode = 'REPLACE', keys = ['view_name'], src_code = 'ddl')\n",
    "res"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.loc[df.table_id == 'BRA05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df.view_name.str.startswith('ODM') & ~df.view_name.str.startswith('V')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the following script is to create the DDL for linage program to process\n",
    "\n",
    "_some defect need to be addressed_\n",
    "1. the ODMV_TAS_TRKHIRE can not be parsed because the alias problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_ddl(ddl_stmt):\n",
    "    ddl_lines = ddl_stmt.split('\\n')\n",
    "    ddl_lines = list( filter(lambda x: x.lstrip()[0:2] != '--'   , ddl_lines) )\n",
    "    ddl_lines = [' ' if i.strip() =='' else i.strip() if i.strip()[-1]=='.' else i.strip()+ ' ' for i in ddl_lines]\n",
    "    ddl = \"\\n\".join(ddl_lines).strip() # turn multiple lines into one single line.\n",
    "    return ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(\"now =\", now)\n",
    "dt_string = now. strftime(\"%Y%m%d\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odmr_text = open('/input/{}'.format(odmr_file), 'r').read()\n",
    "ddls_odmr = re.split('--    View=.*?\\n', odmr_text, flags = re.I)\n",
    "ddls_odmr = ddls_odmr[1:]  #remove the first element\n",
    "print(\"Total number of ddl are : {}\".format(len(ddls_odmr)))\n",
    "ddls_odmr = list(map(proc_ddl, ddls_odmr))\n",
    "ddls_odmr = list(filter(lambda ddl: ddl != '', ddls_odmr))\n",
    "\n",
    "### special handling\n",
    "### special handling\n",
    "ddls_odmr = list(filter(lambda ddl: 'VBPS_LDA' not in ddl, ddls_odmr))  # remove odmv_tas_trkhire\n",
    "ddls_odmr = list(filter(lambda ddl: 'ODMPRD.ODMV_TAS_TRKHIRE' not in ddl, ddls_odmr))  # remove odmv_tas_trkhire\n",
    "### special handling\n",
    "### special handling\n",
    "\n",
    "\n",
    "#ddls_odmr = list(filter(lambda ddl: 'CREATE VIEW ODMPRD.ODMV_EMPLOYEE' not in ddl, ddls_odm))  # remove odmv_tas_trkhire\n",
    "\n",
    "ddls_odmr.append('')\n",
    "list(filter(lambda ddl: 'ODMV_TAS_TRKHIRE' not in ddl, ddls_odmr))\n",
    "final_odmr_ddl = '\\nCOMMIT ; \\n--\\n'.join(ddls_odmr)\n",
    "with open('/result/odmr_views_{}.txt'.format(dt_string), 'w') as f:\n",
    "    f.write(final_odmr_ddl)\n",
    "with open('/result/odmr_views.txt', 'w') as f:\n",
    "    f.write(final_odmr_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Here, prepare some addition DDL for those customized extract interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_exts = {\n",
    "    \"KIW\": 'ODMLD.PROD.SQL(ODMKIWQ)',\n",
    "    'KAR': \"ODMLD.PROD.SQL(ODMARK01)\", \n",
    "#    \"CARD\": \"OPC.PRODJCL.HR(ODMULCRD)\", \n",
    "#    \"WHILELIST\": \"OPC.PRODJCL.HR(ODMULWHL)\",\n",
    "    \"KAP\": 'ODMLD.PROD.SQL(ODMAPK01)', \n",
    "#    \"SMS\": \"ODMLD.PROD.SQL(ODMEYLQ1)\",  Trailer line number\n",
    "#    \"MGT\": \"ODMLD.PROD.SQL(ODMMGTQ1)\",  JCL?\n",
    "#    \"IRON\": \"ODMLD.PROD.SQL(ODMDERPQ)\",  JCL? \n",
    "    \"KIR\": \"ODMLD.PROD.SQL(ODMUKIR)\", \n",
    "    \"KIJ\": \"ODMLD.PROD.SQL(ODMUKIJ)\", \n",
    "    \"KIE\": \"ODMLD.PROD.SQL(ODMUKIE)\"\n",
    "    \n",
    "}\n",
    "cust_exts.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cust_exts = {\n",
    "    \"KIW\": 'ODMLD.PROD.SQL(ODMKIWQ)',\n",
    "    'KAR': \"ODMLD.PROD.SQL(ODMARK01)\", \n",
    "    \"CARD\": \"OPC.PRODJCL.HR(ODMULCRD)\", \n",
    "    \"WHILELIST\": \"OPC.PRODJCL.HR(ODMULWHL)\",\n",
    "    \"KAP\": 'ODMLD.PROD.SQL(ODMAPK01)', \n",
    "    \"SMS\": \"ODMLD.PROD.SQL(ODMEYLQ1)\",  #Trailer line number\n",
    "    \"MGT\": \"ODMLD.PROD.SQL(ODMMGTQ1)\",  #JCL?\n",
    "    \"IRON\": \"ODMLD.PROD.SQL(ODMDERPQ)\",  #JCL? \n",
    "    \"KIR\": \"ODMLD.PROD.SQL(ODMUKIR)\", \n",
    "    \"KIJ\": \"ODMLD.PROD.SQL(ODMUKIJ)\", \n",
    "    \"KIE\": \"ODMLD.PROD.SQL(ODMUKIE)\"\n",
    "    \n",
    "}\n",
    "cust_exts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl_temp = '''CREATE VIEW ODMPRD.{} AS \n",
    "{}\n",
    "COMMIT ;\n",
    "--'''\n",
    "\n",
    "with odm_ftp.odm_ftp_conn('get') as odm_get_file:\n",
    "    [odm_get_file(fm = value, to = '/input/{}.sql'.format(key)) for key, value in cust_exts.items()]\n",
    "ddls = {key: ddl_temp.format(key, open('/input/{}.sql'.format(key), 'r').read().strip()) for key in cust_exts.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('temp.txt', 'w') as f: \n",
    "    ddl_added = '\\n'.join(ddls.values())\n",
    "    print(ddl_added,  file = f )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Need special process for KIE interface since it contains strings like '\"'  '\"\"' etc.. very difficult. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from common_func import odm_conn\n",
    "from common_func import odm_dict\n",
    "with odm_conn.odm_adhoc('prod') as odmprd_adhoc: \n",
    "    result = odmprd_adhoc('select * from odmprd.ODMT_GI_AUTHORITY')\n",
    "    df_c09 = pd.DataFrame(result).applymap(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# odm_dict.refresh()\n",
    "df_tid = odm_dict.odm_tid_df_from_csv()\n",
    "df_col = odm_dict.odm_col_df_from_csv()\n",
    "df_col = df_col.loc[df_col.NAME !=''] # remove those line which could not be found in systable\n",
    "df_tid = df_tid.loc[df_tid.NAME !='']\n",
    "tid_dict = df_tid.set_index('CTID')['CTABNAME'].to_dict()\n",
    "tid_desc_dict = df_tid.set_index('CTID')['TTID'].to_dict()\n",
    "df_col['tid_col'] = df_col.CTID + '.' + df_col.CCOLNAME\n",
    "data_class_dict = df_col.set_index('tid_col').CCLASS.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def ge_ddl(idx, df): # idx and df\n",
    "    if '*' in list(df.NITEM): \n",
    "        col_list = '*'\n",
    "    else: \n",
    "        col_list = ', '.join(df.NITEM)\n",
    "    tb_name = tid_dict.get(idx[1], '')\n",
    "    if tb_name == '':\n",
    "        print(idx, df.NITEM)\n",
    "    #print(idx[1], tb_name)\n",
    "    return '''CREATE VIEW ODMPRD.{} AS \n",
    "SELECT {} \n",
    "from ODMPRD.{}; \n",
    "COMMIT ; \n",
    "--\n",
    "'''.format(idx[0], col_list,tb_name ) if tb_name != '' else None\n",
    "\n",
    "ge_ddl_str = ''\n",
    "for idx, df in df_c09.groupby(['CFDRSRC', 'CTABLE']):\n",
    "    #print(idx)\n",
    "    temp_ddl = ge_ddl(idx, df) \n",
    "    ge_ddl_str = ge_ddl_str + temp_ddl if temp_ddl else ge_ddl_str\n",
    "print(ge_ddl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odm_text = open('/input/{}'.format(odm_file), 'r').read()\n",
    "ddls_odm = re.split('--    View=.*?\\n', odm_text, flags = re.I)\n",
    "ddls_odm = ddls_odm[1:]  #remove the first element\n",
    "print(\"Total number of ddl are : {}\".format(len(ddls_odm)))\n",
    "ddls_odm = list(map(proc_ddl, ddls_odm))\n",
    "ddls_odm = list(filter(lambda ddl: ddl != '', ddls_odm))\n",
    "\n",
    "### special handling\n",
    "### special handling\n",
    "### special handling\n",
    "ddls_odm = list(filter(lambda ddl: 'ODMV_TAS_TRKHIRE' not in ddl, ddls_odm))  # remove odmv_tas_trkhire\n",
    "ddls_odm.append('')\n",
    "list(filter(lambda ddl: 'ODMV_TAS_TRKHIRE' not in ddl, ddls_odm))\n",
    "final_odm_ddl = '\\nCOMMIT ; \\n--\\n'.join(ddls_odm)\n",
    "final_odm_ddl = final_odm_ddl.replace('\"SYSIBM\".', 'SYSIBM.')\n",
    "### special handling#\n",
    "## special handling\n",
    "\n",
    "with open('/result/odm_views_{}.txt'.format(dt_string), 'w') as f:\n",
    "    f.write(final_odm_ddl)\n",
    "    f.write(ddl_added)\n",
    "with open('/result/odm_views.txt', 'w') as f:\n",
    "    f.write(final_odm_ddl)\n",
    "    f.write(ddl_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curation Lineage STEP 2 do the following to generate the lineage information\n",
    "\n",
    "\n",
    "\n",
    "Now, the ddl of ODM and ODMR are in the result/odm_views.txt and result/odmr_views.txt\n",
    "\n",
    "Next, just start the docker image odm-lineage:latest, then the result will be placed in the following 2 files  \n",
    "```\n",
    "cd ~/Documents/GitHub/odm-lineage\n",
    "./test_local.sh\n",
    "\n",
    "odm_views.txt_parse.xlsx  \n",
    "odmr_views.txt_parse.xlsx\n",
    "```  \n",
    "\n",
    "go to the folder , open another termial, use the following command to monitor the proccessing:   \n",
    "```\n",
    "cd ${ODM_DAILY_PUBLIC_ROOT}/result \n",
    "tail -f lineage_log.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
